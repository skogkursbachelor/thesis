\chapter{Quality Assurance and User Feedback}\label{chap:qualityassuranceanduserfeedback}

\textcolor{orange}{NOE TEKST}

\section{Quality Assurance}

\subsection{Documentation}
\textcolor{orange}{kanskje fjerne denne seksjonen?}

Proper documentation is crucial, as there is a possibility that others may use the code in the
future. To address this the code is documented throughout the project. 

The website is documented using JSDoc \textcolor{orange}{skriv mer om dette etter at det er gjort}.  


All tasks will be tracked and recorded as GitHub issues, ensuring a clear
history of the project's progress. 

\subsection{Code Quality} %BEDRE NAVN?

\textcolor{orange}{Dette står i planen: Plan for Inspections & Testing
• Implement CI/CD pipelines on GitHub to automate processes as much as possible, starting
early in development.
• The pipelines will include:
– Static Code Analysis and Linting
– Unit and Integration Testing
– Deployment
• Conduct user testing with the Product Owner and potential end-users once the MVP is
complete. Interviews and follow-ups will be conducted to measure satisfaction and gather
feedback for the MMP.
• For unit and integration testing, we aim for 80\% or higher coverage, with a primary focus on
critical components and an emphasis on test quality over quantity.
• To monitor errors, identify potential availability and integrity issues, and facilitate debugging,
a logging system will be implemented.}

Due to the exploratory nature of the project, particularly the uncertainty around suitable map data sources and integration methods early in development, automated unit and integration testing were not prioritized. Test-driven development was deemed impractical under these conditions, as frequent changes in data formats and system architecture would have led to excessive refactoring and time loss.

Despite the limited use of automated testing, the application has been thoroughly tested manually throughout the development process. Critical components, such as the trafficability classification algorithm, are covered by unit tests to ensure correctness. However, the overall automated test coverage remains low.

In retrospect, a higher level of test automation, particularly end-to-end tests connecting the frontend and backend, would have been beneficial. These could have caught integration issues early, reduced the need for manual testing after each change, and improved confidence during deployment. Automated tests also facilitate easier maintenance and refactoring, which is particularly important for future development and scaling.

\subsubsection*{Linting}

Code linting and formatting were consistently applied to ensure readability and maintain a uniform code style across the project. In the frontend, ESLint runs automatically when files are saved, enforcing common TypeScript conventions. On the backend, Go's built-in gofmt tool is used for formatting, while golangci-lint handles static analysis and linting, both configured to run on save.

\subsubsection*{Performance}

Performance testing was not systematically conducted. The application has only been tested under light concurrent usage by team members. In a production scenario with multiple external users, performance bottlenecks, especially related to external API response times, could emerge. Since the system depends on several external data sources, response latency and availability issues may affect overall performance. One potential improvement would be to locally cache or store relatively static data such as superficial deposits and soil saturation layers, thereby reducing dependency on external APIs and improving load times.

\subsubsection*{Logging}

In the backend server a logging system was implemented \textcolor{orange}{skal dette nevnes her ?}

\section{User Testing}\label{sec:quality_assurance_user_feedback:user_testing}

Due to time constraints and the challenge of recruiting enough relevant participants, we were not able to conduct formal user testing during the project period. However, we recognize that user testing would be highly valuable in the future, both to improve the \acrfull{ux} and to identify additional features that transport managers would find useful in their day-to-day work.

Instead, we relied on iterative feedback from the product owner, which proved essential in guiding the development. This feedback primarily focused on functionality, particularly the need for greater flexibility for transport managers. For example, it was suggested that users should be able to adjust threshold values used in classifying trafficability, allowing them to tailor the system to their operational requirements by setting these thresholds based on their local knowledge and past experience. Feedback also covered the relevance and reliability of data sources used to assess forestry road conditions.

Based on this input, we implemented several concrete changes. Most notably, as mentioned earlier, we added the feature that allows users to customize threshold values for map layers. Additionally, we integrated a soil moisture map layer, which provides transport managers with deeper insight into road conditions and supports more informed decisions.

Toward the end of the project, we presented the prototype to two senior leaders in the forest owners' association. Their feedback was very positive, and they expressed that the solution could be a highly useful tool for the forestry industry. During the presentation, we emphasized the system's flexible architecture, which makes it relatively straightforward to incorporate additional map layers or data sources in the future to enhance both accuracy and functionality.

\subsection{Result}

\textcolor{orange}{NOE TEKST}

\subsection{Product Iteration and Polish}

\textcolor{orange}{NOE TEKST}
